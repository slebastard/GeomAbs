{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometry of abstraction - DNN for MNIST recognition and information structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geometry of abstraction in hippocampus and prefrontal cortex <br>\n",
    "Silvia Bernardi, Marcus K Benna, Mattia Rigotti, Jérôme Munuera, Stefano Fusi, Daniel Salzman <br>\n",
    "bioRxiv 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "lib_path = os.path.abspath('../methods')\n",
    "sys.path.insert(0, lib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Model\n",
    "from data_tools import ImageDataset\n",
    "import data_tools as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "filt_labels = range(8)\n",
    "mnist_8 = ImageDataset(x_train, y_train, x_test, y_test, filt_labels=filt_labels, spl=0.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading MNIST data, unfolding square to long representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently dichotomies will only be binary\n",
    "mnist8_parity = [list(map(lambda x: 2*x, range(4))), list(map(lambda x: 2*x + 1, range(4)))]\n",
    "mnist8_smallness = [range(0,4), range(4,8)]\n",
    "mnist8_prod = [set(s1).intersection(set(s2)) for s2 in mnist8_smallness for s1 in mnist8_parity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_8.build_dichLabels(mnist8_smallness, 'smaller_than_4')\n",
    "mnist_8.build_dichLabels(mnist8_parity, 'parity')\n",
    "\n",
    "mnist_8.hstack_dichs('parity', 'smaller_than_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alright, let's start with a three layer NN\n",
    "w_in = mnist_8.tot_dim\n",
    "w_1 = 100\n",
    "w_2 = 100\n",
    "w_out = 4\n",
    "\n",
    "max_epochs = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Let's reproduce the DNN that was used in the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_from_paper = Sequential([\n",
    "    Dense(w_1, input_shape=(w_in,)),\n",
    "    Activation('tanh'),\n",
    "    Dense(w_2),\n",
    "    Activation('tanh'),\n",
    "    Dense(4),\n",
    "    Activation('tanh')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(dnn_from_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(mnist_8, dich_name='parity_hstack_smaller_than_4', epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(mnist_8, dich_name='parity_hstack_smaller_than_4', batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sample_eval(mnist_8, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Dimensionality reduction on the representations of the layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so now let's try to use dimensionality reduction to analyze the content of the different layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import shuffle\n",
    "\n",
    "spl_size = 75\n",
    "spl_ids = np.arange(mnist_8.n_train)\n",
    "shuffle(spl_ids)\n",
    "spl_ids = spl_ids[:spl_size]\n",
    "\n",
    "mnist_8.spl = {\n",
    "    'x': mnist_8.train['x'][spl_ids],\n",
    "    'y': mnist_8.train['y'][spl_ids]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca2 = PCA(n_components=2)\n",
    "rprs1 = model.get_repr(mnist_8, mnist_8.spl, pca2)\n",
    "fig1 = model.plot_reprs(mnist_8, mnist_8.spl, pca2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lay_id, rpr in enumerate(rprs1):\n",
    "    print('Layer {0:d} - {1:.1f}% 2d var - {2:.1f}% + {3:.1f}%'.format(lay_id, 100*(rpr['reduced']['expl_var'][0]+rpr['reduced']['expl_var'][1]), 100*rpr['reduced']['expl_var'][0], 100*rpr['reduced']['expl_var'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "pca3 = PCA(n_components=3)\n",
    "rprs2 = model.get_repr(mnist_8, mnist_8.spl, pca3)\n",
    "fig2 = model.plot_reprs(mnist_8, mnist_8.spl, pca3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lay_id, rpr in enumerate(rprs2):\n",
    "    print('Layer {0:d} - {1:.1f}% 3d var - {2:.1f}% + {3:.1f}% + {4:.1f}%'.format(lay_id, 100*(rpr['reduced']['expl_var'][0]+rpr['reduced']['expl_var'][1]+rpr['reduced']['expl_var'][2]), 100*rpr['reduced']['expl_var'][0], 100*rpr['reduced']['expl_var'][1], 100*rpr['reduced']['expl_var'][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Analysis in terms of cross-condition generalization performance (CCGP) and parallelism score (PS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paralellism Score (PS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PScores = model.get_all_PS(mnist_8, rprs1, lay_id=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Creates subplots and unpacks the output array immediately\n",
    "ps = [pscore for pscore in PScores.values()]\n",
    "ps_top_dichs = [pscore for pscore in PScores.keys()]\n",
    "plt.plot(ps, marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rk, dich in enumerate(ps_top_dichs[:8]):\n",
    "    print(\"Dich: {0:s} ranks {1:d} (PS={2:f})\".format(str(dich), rk+1, ps[rk]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Condition Generalization Performance (CCGP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(w_in, w_1, w_2, w_out) = (mnist_8.tot_dim, 100, 100, 4)\n",
    "max_epochs = 400\n",
    "max_epochs = 400\n",
    "dnn_hstack_classif = Sequential([\n",
    "    Dense(w_1, input_shape=(w_in,)),\n",
    "    Activation('tanh'),\n",
    "    Dense(w_2),\n",
    "    Activation('tanh'),\n",
    "    Dense(w_out),\n",
    "    Activation('softmax')\n",
    "])\n",
    "\n",
    "ccgp_model = Model(dnn_hstack_classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import types\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "def _patch_get_dich_CCGP(self, ds, dich, n_labels_retained=2):\n",
    "\t\t\"\"\"\n",
    "\t\tCCGP is defined as the capacity to generalize on an unseen condition from training on a subset of possible conditions\n",
    "\t\t\"\"\"\n",
    "\t\tdich_0 = dich\n",
    "\t\tdich_1 = np.setdiff1d(ds.labels, dich_0)\n",
    "\t\tassert len(dich_0) == len(dich_1)\n",
    "\n",
    "\t\t# For now, labels will only be retained from dich_1 and will be random within dich_1\n",
    "\t\tretained_labels = np.random.choice(dich_1, size=n_labels_retained, replace=False)\n",
    "\t\ttrain_labels = np.setdiff1d(ds.labels, retained_labels)\n",
    "\n",
    "\t\tds_gnr = ds.generate_gnr_set(train_labels)\n",
    "\t\t#ds_gnr.spl = ds.spl\n",
    "\n",
    "\t\tdich_name = ''.join([str(x) for x in dich_0])\n",
    "\t\tds_gnr.build_dichLabels([dich_0, dich_1], dich_name)\n",
    "\t\tds_gnr.train['dichs'][dich_name] = ds_gnr.train['dichs'][dich_name][:,0]\n",
    "\t\tds_gnr.test['dichs'][dich_name] = ds_gnr.test['dichs'][dich_name][:,0]\n",
    "\t\tds_gnr.gnr['dichs'][dich_name] = ds_gnr.gnr['dichs'][dich_name][:,0]\n",
    "\t\t\n",
    "\t\t# Create the linear classifier and train it on the submodel instance\n",
    "\t\tsvc = LinearSVC()\n",
    "\t\trpr = {\n",
    "\t\t\t'train': self.get_repr(ds_gnr, ds_gnr.train, dimRed=None),\n",
    "\t\t\t'test': self.get_repr(ds_gnr, ds_gnr.test, dimRed=None),\n",
    "\t\t\t'gnr': self.get_repr(ds_gnr, ds_gnr.gnr, dimRed=None)\n",
    "\t\t}\n",
    "\n",
    "\t\tCCGP_across_layers = []\n",
    "\n",
    "\t\tfor lay_id in range(self.n_layers):\n",
    "\t\t\t#pca2 = PCA(n_components=2)\n",
    "\t\t\t#train_red_repr = pca2.fit_transform(rpr['train'][lay_id]['original']['repr'])\n",
    "            #svc.fit(train_red_repr, ds_gnr.train['dichs'][dich_name])\n",
    "\t\t\tsvc.fit(rpr['train'][lay_id]['original']['repr'], ds_gnr.train['dichs'][dich_name])\n",
    "\n",
    "\t\t\ttrain_score = svc.score(rpr['train'][lay_id]['original']['repr'], ds_gnr.train['dichs'][dich_name])\n",
    "\t\t\ttest_score = svc.score(rpr['test'][lay_id]['original']['repr'], ds_gnr.test['dichs'][dich_name])\n",
    "\t\t\tgnr_score = svc.score(rpr['gnr'][lay_id]['original']['repr'], ds_gnr.gnr['dichs'][dich_name])\n",
    "\n",
    "\t\t\t# Evaluate performance\n",
    "\t\t\tCCGP_across_layers.append({\n",
    "\t\t\t\t'train_labels': train_labels,\n",
    "\t\t\t\t'retained_labels': retained_labels,\n",
    "\t\t\t\t'train_score': train_score,\n",
    "\t\t\t\t'test_score': test_score,\n",
    "\t\t\t\t'gnr_score': gnr_score\n",
    "\t\t\t})\n",
    "\n",
    "\t\treturn CCGP_across_layers\n",
    "    \n",
    "ccgp_model.get_dich_CCGP  = types.MethodType(_patch_get_dich_CCGP, ccgp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _patch_generate_gnr_set(self, train_labels, normalize=True):\n",
    "\tgnr_labels = np.setdiff1d(self.labels, train_labels)\n",
    "\tin_filt_train = np.isin(self.train['y'], train_labels)\n",
    "\tx_filt_train = np.where(in_filt_train)[0]\n",
    "\tx_train = self.train['x'].take(x_filt_train, axis=0)\n",
    "\tif normalize:\n",
    "\t\tx_train = normalize_array(x_train)\n",
    "\n",
    "\tdim_list = [d for d in self.axes_dim]\n",
    "\tdtuple_train = dim_list.copy()\n",
    "\tdtuple_train.insert(0, x_train.shape[0])\n",
    "\tdtuple_train = tuple(dtuple_train)\n",
    "\tx_train = x_train.reshape(dtuple_train)\n",
    "\ty_train = self.train['y'][in_filt_train]\n",
    "\t\n",
    "\tin_filt_test = np.isin(self.test['y'], train_labels)\n",
    "\tx_filt_test = np.where(in_filt_test)[0]\n",
    "\tx_test = self.test['x'].take(x_filt_test, axis=0)\n",
    "\tif normalize:\n",
    "\t\tx_test = normalize_array(x_test)\n",
    "\n",
    "\tdtuple_test = dim_list.copy()\n",
    "\tdtuple_test.insert(0, x_test.shape[0])\n",
    "\tdtuple_test = tuple(dtuple_test)\n",
    "\tx_test = x_test.reshape(dtuple_test)\n",
    "\ty_test = self.test['y'][in_filt_test]\n",
    "\t\n",
    "\tx_filt_gnrtrain = np.where(~in_filt_train)[0]\n",
    "\tx_filt_gnrtest = np.where(~in_filt_test)[0]\n",
    "\tx_gnr = self.train['x'].take(x_filt_gnrtrain, axis=0)\n",
    "\tx_gnr = np.vstack((x_gnr, self.test['x'].take(x_filt_gnrtest, axis=0)))\n",
    "\tif normalize:\n",
    "\t\tx_gnr = normalize_array(x_gnr)\n",
    "\t\t\n",
    "\tdtuple_gnr = dim_list.copy()\n",
    "\tdtuple_gnr.insert(0, x_gnr.shape[0])\n",
    "\tdtuple_gnr = tuple(dtuple_gnr)\n",
    "\tx_gnr = x_gnr.reshape(dtuple_gnr)\n",
    "\ty_gnr = self.train['y'][~in_filt_train]\n",
    "\ty_gnr = np.hstack((y_gnr, self.test['y'][~in_filt_test]))\n",
    "\t\n",
    "\treturn ImageDataset(x_train, y_train, x_test, y_test, x_gnr, y_gnr)\n",
    "\n",
    "mnist_8.generate_gnr_set = types.MethodType(_patch_generate_gnr_set, mnist_8)\n",
    "\n",
    "def normalize_array(ar):\n",
    "\t\"\"\"\n",
    "\tEach row must be an entry, each column must be a dimension\n",
    "\t\"\"\"\n",
    "\tar_mean = np.mean(ar, axis=0)\n",
    "\tnar = ar - ar_mean\n",
    "\tar_min = np.min(nar, axis=0)\n",
    "\tar_max = np.max(nar, axis=0)\n",
    "\tnar = np.divide(2*nar, ar_max-ar_min, out=np.zeros_like(nar), where=(ar_max!=ar_min)) - np.divide(ar_max+ar_min, ar_max-ar_min, out=np.zeros_like(nar), where=(ar_max!=ar_min))\n",
    "\treturn nar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "CCGP1_across_layers = ccgp_model.get_dich_CCGP(mnist_8, (0, 2, 4, 6), n_labels_retained=1)\n",
    "dur1 = time() - start\n",
    "print(\"CCGP_1 computation on parity dichotomy took {0:.1f}s\".format(dur1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "CCGP2_across_layers = ccgp_model.get_dich_CCGP(mnist_8, (0, 2, 4, 6), n_labels_retained=2)\n",
    "dur2 = time() - start\n",
    "print(\"CCGP_2 computation on parity dichotomy took {0:.1f}s\".format(dur2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dichs_to_include = [tuple(mnist8_parity[0]), tuple(mnist8_smallness[0])]\n",
    "perfs = ccgp_model.get_all_CCGP(mnist_8, max_n_dichs=20, dichs_to_include=dichs_to_include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccgp_scores = []\n",
    "df_perf = []\n",
    "ccgp_top_dichs = []\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8*ccgp_model.n_layers))\n",
    "axes = []\n",
    "gs1 = gridspec.GridSpec(ccgp_model.n_layers,1)\n",
    "gs1.update(wspace=0.025, hspace=0.2)\n",
    "\n",
    "for lay_id, _ in enumerate(ccgp_model.layers):\n",
    "    print(\"LAYER {0:d} - Representation CCGP score\".format(lay_id))\n",
    "    \n",
    "    ax = plt.subplot(gs1[lay_id])\n",
    "    ccgp_scores.append({k: v[lay_id] for k,v in perfs.items()})\n",
    "    df_perf.append(pd.DataFrame.from_dict(ccgp_scores[lay_id], orient='index'))\n",
    "    ccgp = [score for score in df_perf[lay_id]['gnr_score']]\n",
    "    sort_ids = np.argsort(ccgp).tolist()\n",
    "    sort_ids.reverse()\n",
    "    ccgp = [ccgp[i] for i in sort_ids]\n",
    "    ccgp_top_dichs.append(df_perf[lay_id].index)\n",
    "    ccgp_top_dichs[lay_id] = [ccgp_top_dichs[lay_id][i] for i in sort_ids]\n",
    "    ax.plot(ccgp, linestyle='', marker='+')\n",
    "    \n",
    "    parity_rank = ccgp_top_dichs[lay_id].index((0, 2, 4, 6))\n",
    "    greatness_rank = ccgp_top_dichs[lay_id].index((0, 1, 2, 3))\n",
    "    ax.plot(parity_rank, ccgp[parity_rank], marker='+', color='red', markersize=10, markeredgewidth=4)\n",
    "    ax.plot(greatness_rank, ccgp[greatness_rank], marker='+', color='blue', markersize=10, markeredgewidth=4)\n",
    "    \n",
    "    print(\"Top dichotomies for CCGP\\n________________________\")\n",
    "    for rk, dich in enumerate(ccgp_top_dichs[lay_id][:8]):\n",
    "        print(\"Dich: {0:s} ranks {1:d} (CCGP={2:f})\".format(str(dich), rk+1, ccgp[rk]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rk, dich in enumerate(ccgp_top_dichs_l5[:8]):\n",
    "    print(\"Dich: {0:s} ranks {1:d} (CCGP={2:f})\".format(str(dich), rk+1, ps[rk]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
